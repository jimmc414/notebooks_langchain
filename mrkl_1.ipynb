{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from langchain import LLMMathChain, OpenAI, SerpAPIWrapper, SQLDatabase, SQLDatabaseChain\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side.', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [], [], [], [], [], [], [], [], [], [], [], [], []], llm_output={'token_usage': {'prompt_tokens': 4, 'completion_tokens': 38, 'total_tokens': 42}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)\n",
    "llm._generate(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side!', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [], [], [], [], [], [], [], [], [], [], [], [], []], llm_output={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 4, 'total_tokens': 42}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.generate(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [], [], [], [], [], [], [], [], [], [], [], [], []], llm_output={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 4, 'total_tokens': 24}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0) \n",
    "llm.generate(\"Tell me a joke\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0)   #,openai_api_key=openai_api_key)\n",
    "search = SerpAPIWrapper() #serpapi_api_key=serpapi_api_key\n",
    "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "db = SQLDatabase.from_uri(\"sqlite:////home/rubensmau/luby/langchain/Chinook.db\") \n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events. You should ask targeted questions\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"FooBar DB\",\n",
    "        func=db_chain.run,\n",
    "        description=\"useful for when you need to answer questions about FooBar. Input should be in the form of a question containing full context\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrkl = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True,return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZeroShotAgent(llm_chain=LLMChain(memory=None, callback_manager=SharedCallbackManager(ignore_llm=False, ignore_chain=False, ignore_agent=False), verbose=False, prompt=PromptTemplate(input_variables=['input', 'agent_scratchpad'], output_parser=None, template='Answer the following questions as best you can. You have access to the following tools:\\n\\nSearch: useful for when you need to answer questions about current events. You should ask targeted questions\\nCalculator: useful for when you need to answer questions about math\\nFooBar DB: useful for when you need to answer questions about FooBar. Input should be in the form of a question containing full context\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Search, Calculator, FooBar DB]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}', template_format='f-string'), llm=OpenAI(cache=None, verbose=False, callback_manager=SharedCallbackManager(ignore_llm=False, ignore_chain=False, ignore_agent=False), client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, batch_size=20, request_timeout=None, logit_bias={}), output_key='text'), return_values=['output'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: useful for when you need to answer questions about current events. You should ask targeted questions\n",
      "Calculator: useful for when you need to answer questions about math\n",
      "FooBar DB: useful for when you need to answer questions about FooBar. Input should be in the form of a question containing full context\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator, FooBar DB]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "res = mrkl.agent.llm_chain.prompt.template\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='.bar\\n\\nFoo.bar is a common phrase used to refer to something that is not easily understood or is confusing. It can also be used to describe something that is difficult to explain or comprehend.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='-nav\">\\n            <li class=\"nav-item\">\\n              <a class=\"nav-link\" href=\"index.php\">Home</a>\\n            </li>\\n            <li class=\"nav-item\">\\n              <a class=\"nav-link\" href=\"about.php\">About</a>\\n            </li>\\n            <li class=\"nav-item\">\\n              <a class=\"nav-link\" href=\"contact.php\">Contact</a>\\n            </li>\\n            <li class=\"nav-item\">\\n              <a class=\"nav-link\" href=\"login.php\">Login</a>\\n            </li>\\n            <li class=\"nav-item\">\\n              <a class=\"nav-link\" href=\"register.php\">Register</a>\\n            </li>\\n          </ul>\\n        </div>\\n      </div>\\n    </nav>\\n\\n    <!-- Page Content -->\\n    <div class=\"container\">\\n\\n      <div class=\"row\">\\n\\n        <!-- Post Content Column -->\\n        <div class=\"col-lg-8\">\\n\\n          <!-- Title -->\\n          <h1 class=\"mt-4\">', generation_info={'finish_reason': 'length', 'logprobs': None})], [Generation(text='.bar\\n\\nFoo.bar is a common phrase used to refer to something that is not easily understood or is confusing. It can also be used to describe something that is difficult to explain or comprehend.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 3, 'total_tokens': 343}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.generate([\"foo\", \"bar\", \"foo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailableError",
     "evalue": "The server is overloaded or not ready yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[39m.\u001b[39;49mgenerate(\u001b[39m\"\u001b[39;49m\u001b[39mWho is Olivia Wilde\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms boyfriend?\u001b[39;49m\u001b[39m\"\u001b[39;49m,stop\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:81\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     80\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:77\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     74\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     78\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/openai.py:158\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    156\u001b[0m _keys \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcompletion_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtotal_tokens\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m _prompts \u001b[39min\u001b[39;00m sub_prompts:\n\u001b[0;32m--> 158\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    159\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    160\u001b[0m     _keys_to_use \u001b[39m=\u001b[39m _keys\u001b[39m.\u001b[39mintersection(response[\u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    390\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    393\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:410\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m OpenAIResponse(\u001b[39mNone\u001b[39;00m, rheaders)\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m rcode \u001b[39m==\u001b[39m \u001b[39m503\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mServiceUnavailableError(\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe server is overloaded or not ready yet.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m         rbody,\n\u001b[1;32m    413\u001b[0m         rcode,\n\u001b[1;32m    414\u001b[0m         headers\u001b[39m=\u001b[39mrheaders,\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(rbody, \u001b[39m\"\u001b[39m\u001b[39mdecode\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
     ]
    }
   ],
   "source": [
    "llm.generate(\"Who is Olivia Wilde's boyfriend?\",stop='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\n",
      "Action: Search\n",
      "Action Input: \"Who is Olivia Wilde's boyfriend?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHarry Styles\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Harry Styles' age\n",
      "Action: Search\n",
      "Action Input: \"How old is Harry Styles?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m28 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate 28 raised to the 0.23 power\n",
      "Action: Calculator\n",
      "Action Input: 28^0.23\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "28^0.23"
     ]
    },
    {
     "ename": "ServiceUnavailableError",
     "evalue": "The server is overloaded or not ready yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m mrkl(\u001b[39m\"\u001b[39;49m\u001b[39mWho is Olivia Wilde\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms boyfriend? What is his current age raised to the 0.23 power?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:146\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:142\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    139\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, inputs\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py:287\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    286\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 287\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    288\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/agent.py:281\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_start(\n\u001b[1;32m    277\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(tool\u001b[39m.\u001b[39mfunc)[:\u001b[39m60\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m}, output, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     )\n\u001b[1;32m    279\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mfunc(output\u001b[39m.\u001b[39;49mtool_input)\n\u001b[1;32m    282\u001b[0m     color \u001b[39m=\u001b[39m color_mapping[output\u001b[39m.\u001b[39mtool]\n\u001b[1;32m    283\u001b[0m     return_direct \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39mreturn_direct\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:172\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    171\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    174\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:146\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:142\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    139\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, inputs\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:55\u001b[0m, in \u001b[0;36mLLMMathChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_text(inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key])\n\u001b[0;32m---> 55\u001b[0m t \u001b[39m=\u001b[39m llm_executor\u001b[39m.\u001b[39;49mpredict(question\u001b[39m=\u001b[39;49minputs[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_key], stop\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m```output\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_text(t, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     90\u001b[0m     \u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:146\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    145\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/base.py:142\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    139\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, inputs\n\u001b[1;32m    140\u001b[0m     )\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:87\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply([inputs])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:78\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, input_list: List[Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m     77\u001b[0m     \u001b[39m\"\"\"Utilize the LLM generate method for speed gains.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(input_list)\n\u001b[1;32m     79\u001b[0m     outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     80\u001b[0m     \u001b[39mfor\u001b[39;00m generation \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mgenerations:\n\u001b[1;32m     81\u001b[0m         \u001b[39m# Get the text of the top generated string.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/llm.py:73\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf `stop` is present in any inputs, should be present in all.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m     prompts\u001b[39m.\u001b[39mappend(prompt)\n\u001b[0;32m---> 73\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:81\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     80\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/base.py:77\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m     74\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m     78\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/llms/openai.py:158\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    156\u001b[0m _keys \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcompletion_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt_tokens\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtotal_tokens\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m _prompts \u001b[39min\u001b[39;00m sub_prompts:\n\u001b[0;32m--> 158\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    159\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    160\u001b[0m     _keys_to_use \u001b[39m=\u001b[39m _keys\u001b[39m.\u001b[39mintersection(response[\u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:115\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    107\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39mAPIRequestor(\n\u001b[1;32m    108\u001b[0m     api_key,\n\u001b[1;32m    109\u001b[0m     api_base\u001b[39m=\u001b[39mapi_base,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m--> 115\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    117\u001b[0m     url,\n\u001b[1;32m    118\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    119\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    120\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    121\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    122\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    126\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:181\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    161\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    162\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    172\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    173\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:396\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    389\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    390\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    392\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    393\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    397\u001b[0m             result\u001b[39m.\u001b[39;49mcontent, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    398\u001b[0m         ),\n\u001b[1;32m    399\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/api_requestor.py:410\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[39mreturn\u001b[39;00m OpenAIResponse(\u001b[39mNone\u001b[39;00m, rheaders)\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m rcode \u001b[39m==\u001b[39m \u001b[39m503\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mServiceUnavailableError(\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe server is overloaded or not ready yet.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m         rbody,\n\u001b[1;32m    413\u001b[0m         rcode,\n\u001b[1;32m    414\u001b[0m         headers\u001b[39m=\u001b[39mrheaders,\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(rbody, \u001b[39m\"\u001b[39m\u001b[39mdecode\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
     ]
    }
   ],
   "source": [
    "response = mrkl(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(json\u001b[39m.\u001b[39mdumps(response[\u001b[39m\"\u001b[39m\u001b[39mintermediate_steps\u001b[39m\u001b[39m\"\u001b[39m], indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(response[\"intermediate_steps\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the ages of Prince Harry and his wife\n",
      "Action: Search\n",
      "Action Input: \"Prince Harry age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m38 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out the age of Prince Harry's wife\n",
      "Action: Search\n",
      "Action Input: \"Meghan Markle age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m41 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the ages of both Prince Harry and his wife\n",
      "Action: Calculator\n",
      "Action Input: 38 * 41\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "38 * 41\u001b[32;1m\u001b[1;3m\n",
      "Answer: 1558\u001b[0m\n",
      "\u001b[1m> Finished LLMMathChain chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1558\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1558\u001b[0m\n",
      "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1558'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"What is Prince Harry of England's wife age multiplied to the princeÂ´s age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the artist's full name and then search the FooBar database for their albums.\n",
      "Action: Search\n",
      "Action Input: \"The Storm Before the Calm\" artist\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAlanis Morissette - the storm before the calm - Amazon.com Music.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now need to search the FooBar database for Alanis Morissette's albums.\n",
      "Action: FooBar DB\n",
      "Action Input: What albums of Alanis Morissette are in the FooBar database?\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What albums of Alanis Morissette are in the FooBar database? \n",
      "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT Title FROM Album INNER JOIN Artist ON Album.ArtistId = Artist.ArtistId WHERE Artist.Name = 'Alanis Morissette';\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Jagged Little Pill',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m The album 'Jagged Little Pill' by Alanis Morissette is in the FooBar database.\u001b[0m\n",
      "\u001b[1m> Finished SQLDatabaseChain chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m The album 'Jagged Little Pill' by Alanis Morissette is in the FooBar database.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Alanis Morissette is the artist who recently released an album called 'The Storm Before the Calm' and the album 'Jagged Little Pill' by Alanis Morissette is in the FooBar database.\u001b[0m\n",
      "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Alanis Morissette is the artist who recently released an album called 'The Storm Before the Calm' and the album 'Jagged Little Pill' by Alanis Morissette is in the FooBar database.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"What is the full name of the artist who recently released an album called 'The Storm Before the Calm' and are they in the FooBar database? If so, what albums of theirs are in the FooBar database?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use FooBar DB to get the artist name, then use Search to get the birthdate\n",
      "Action: FooBar DB\n",
      "Action Input: What is the name of an artist in the FooBar database beginning with Alanis?\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What is the name of an artist in the FooBar database beginning with Alanis? \n",
      "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT Name FROM Artist WHERE Name LIKE 'Alanis%';\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('Alanis Morissette',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m Alanis Morissette\u001b[0m\n",
      "\u001b[1m> Finished SQLDatabaseChain chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m Alanis Morissette\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I need to use Search to get the birthdate\n",
      "Action: Search\n",
      "Action Input: When was Alanis Morissette born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJune 1, 1974\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Alanis Morissette was born on June 1, 1974.\u001b[0m\n",
      "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Alanis Morissette was born on June 1, 1974.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"Retrieve from FooBar artist database for a name beginning with Alanis, and then search her birthdate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mrkl.run(\"What albums of The Black Crowes are in the FooBar database? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to search for the band names first, then check the FooBar database for their albums\n",
      "Action: Search\n",
      "Action Input: 4 band names from Atlanta, USA\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIn the early 1980s, Atlanta was the home of a thriving pop and new wave music scene featuring such bands as The Fans, The Brains, The Producers, The Raves, Baby and the Pacifiers, The Razor Boys, The Neuz, Desperate Angel, Samurai Catfish, Heathen Girls and Face of Concern.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I need to check the FooBar database for their albums\n",
      "Action: FooBar DB\n",
      "Action Input: What albums were released by The Fans, The Brains, The Producers, and The Raves?\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "What albums were released by The Fans, The Brains, The Producers, and The Raves? \n",
      "SQLQuery:\u001b[32;1m\u001b[1;3m SELECT Album.Title FROM Album INNER JOIN Artist ON Album.ArtistId = Artist.ArtistId WHERE Artist.Name IN ('The Fans', 'The Brains', 'The Producers', 'The Raves');\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m No albums were released by The Fans, The Brains, The Producers, and The Raves.\u001b[0m\n",
      "\u001b[1m> Finished SQLDatabaseChain chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m No albums were released by The Fans, The Brains, The Producers, and The Raves.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: No albums were released by The Fans, The Brains, The Producers, and The Raves.\u001b[0m\n",
      "\u001b[1m> Finished AgentExecutor chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No albums were released by The Fans, The Brains, The Producers, and The Raves.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrkl.run(\"Search me 4 band names from Atlanta,USA. Then, check in the FooBar database their albums, for each of these band names\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dcacae4b209be26253afbad938ed606d8633cbdbf64a21e50a3f0fad9ec4373"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
